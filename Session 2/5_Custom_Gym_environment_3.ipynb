{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Goal**: Wrap an environment using Gymnasium wrapper and use Stable Baselines 3 to solve it."]},{"cell_type":"markdown","metadata":{},"source":["### Import"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pickle\n","\n","import gymnasium as gym\n","import numpy as np\n","from gymnasium.spaces import Box, Discrete\n","from matplotlib import pyplot as plt\n","from stable_baselines3 import PPO, DQN\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["### Subtract coin environment"]},{"cell_type":"markdown","metadata":{},"source":["**Task**: Implement a coin problem of your design"]},{"cell_type":"markdown","metadata":{},"source":["### Gymnasium wrapper"]},{"cell_type":"markdown","metadata":{},"source":["A Gymnasium wrapper that discretise the observation"]},{"cell_type":"markdown","metadata":{},"source":["**Question**: This code works for the Coin problem implemented in 4_Custom_Gym_environment_2. Does it still work for your environment?"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class DiscreteObsWarpper(gym.Wrapper):\n","    def __init__(self, env: gym.Env):\n","        # This makes orginal env function available\n","        super().__init__(env)\n","\n","        # Discretise the observation space\n","        self.observation_space = Discrete(1100)\n","        self.state_bins = np.linspace(-1, 10, 1101)\n","\n","    def reset(self, seed=None, amount_to_pay=None):\n","        # Calling the original env.reset()\n","        obs, info = self.env.reset(seed=seed, amount_to_pay=amount_to_pay)\n","        obs = self.discretize_state(obs, self.state_bins)\n","        return obs, info\n","\n","    def step(self, action):\n","        # Calling the original env.step()\n","        obs, reward, terminated, truncated, info = self.env.step(action)\n","        obs = self.discretize_state(obs, self.state_bins)\n","        return obs, reward, terminated, truncated, info\n","\n","    # Descritise states\n","    def discretize_state(self, state, state_bins):\n","        return np.digitize(state, state_bins) - 1"]},{"cell_type":"markdown","metadata":{},"source":["### Solve problem with DRL using Stable baselines with PPO"]},{"cell_type":"markdown","metadata":{},"source":["**Task**: Solve your wrapped environment using Stable baselines with PPO"]},{"cell_type":"markdown","metadata":{},"source":["### Test - trained model - PPO"]},{"cell_type":"markdown","metadata":{},"source":["**Task**: Test your train model"]},{"cell_type":"markdown","metadata":{},"source":["**Task**: Try using other DRL algorithm other than PPO. This documentation link might be helfpul: https://stable-baselines3.readthedocs.io/en/master/ "]}],"metadata":{"kernelspec":{"display_name":"RLPractical","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}
